---
layout: default
title: About
nav_order: 1
description: "Description of the AICA crash course on Human-AI interaction (Summer Semester 2025)"
permalink: /
---

# AI in culture and arts -  Human-AI interaction (tech crash course)
{: .no_toc}


## ðŸ“° Announcements
{: .no_toc }

04.03.2025 - Save the date! The tech crash course on AI in Culture and Arts is coming soon. First bloc will be on **Wednesday, April 9th** and **Thursday, April 10th, 2025**.

---

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---
## What is AICA? 

The Digitization College "Artificial Intelligence in Culture and Arts" (AICA) aims to equip students at the [University of Music and Performing Arts Munich](https://hmtm.de/) (HMTM) and [Hochschule MÃ¼nchen University of Applied Sciences](https://www.hm.edu/en/index.en.html) (HM) with necessary skills to impact AI innovations in the creative and cultural industries.

[Learn more about AICA](https://www.wavelab.io/aica/){: .btn .btn-green
 target="_blank"}


## What is the crash course on Human-AI interaction ?

Artificial intelligence (AI) is increasingly impacting the cultural and creative sectors. In particular, machine learning algorithms can now generate unprecedented synthetic media, transforming how we create, produce, and distribute art and culture. Students must develop a theoretical and practical understanding of machine learning to comprehend such transformative technology and foster the development of meaningful human-AI interactions.
This course addresses this need and delves into interactive machine learning for the cultural and creative sectors. The course is intended for art, cultural management, design, and computer science students. After this course, students will master the theoretical and technological foundations of machine learning, be able to train and (critically) evaluate machine learning models, and deploy them in meaningful interactive systems.
The course is structured in three 2-day blocks (6 days in total). Each block provides theoretical lectures and hands-on activities to develop interactive machine-learning systems for image, sound, and text-based applications in the creative and cultural sectors. Every teaching day starts with a lecture and discussion in the morning, followed by a hands-on session on the same topic in the afternoon.

The AICA tech crash course will be hosted at the Wavelab, in the Summer Semester, **starting April 2025**.


## Learning outcomes

After successful participation in this course, students are able to:

- Understand the history and current state of AI: students will be able to explain the different waves of AI (symbolic, connectionist), precisely identify machine learning algorithms, and explain their distinctive characteristics (dataset, optimization, loss, etc.).
- Trainand (critically) evaluate machinelearning algorithm: students will be able to explain and apply the main steps of the development cycle of machine learning, from data collection, analysis, preprocessing, training, and evaluation. They will be able to critically examine a learning curve and performance metrics to assess the performance of their machine-learning models. Furthermore, they will be able to critically discuss the limitations of their model from the content of their dataset and from the perspective of bias and fairness.
- Create interactive machine learning systems: students can design and implement interactive machine learning systems for image, sound, and text-based applications in the creative and cultural sectors. Three examples of interactive systems will be showcased in this course: a teachable image classifier, a gesture-to-sound synthesizer, and a tool for semantic and multi- modal exploration of museum archives. Students already familiar with programming and ma- chine learning will be able to dive deeper into the design and development of novel interactions with machine learning algorithms.

## Prerequisites

The module is designed as an interdisciplinary venue that brings together a range of perspective.
It is aimed at all students enrolled in a third-year Bachelor's program at Hochschule MÃ¼nchen University of Applied Sciences (HM) or the Hochschule fÃ¼r Musik und Theater MÃ¼nchen (HMTM). Students in Master's programs are also welcome. Students with prior computer science and machine learning knowledge will be assigned dedicated and more advanced activities to develop interactive ML systems using the open source [Marcelle toolkit](https://marcelle.dev/).

To apply, please refer to the [Subscription section]({% link content/subscription.md %}).

## Course content

Structured over three 2-day blocks (6 days in total), the course addresses:

1. **Introduction**: This introductory block focuses on image classification using machine learning. After a general introduction to AI's history and current state, participants will explore the machine learning development cycle, engaging with dedicated interactive applications (made with Marcelle) and computational notebooks in Python. The hands-on session will focus on training and evaluating museum artifacts using open-access and open-source datasets (MAMe, Smithsonian Open Acces).
2. **Sound / Music**: The two-day AI Audio section of the AICA Tech Crash Course focuses on the fundamentals of artificial intelligence in audio processing. We start by introducing key audio data concepts and foundational AI techniques. Participants will explore crucial principles through interactive examples covering various applications, including speech recognition, music synthesis, and audio style transfer. Throughout the course, attendees will have ample opportunities to experiment with practical, hands-on demonstrations. The objective is to provide participants with a thorough understanding of AI-driven audio processing and equip them with the necessary skills to perform their own creative experiments.
3. **Image**: In the two-day AI Image section we will explore the creative potential of current AI image generation systems for artistic and design processes in a practical way. Through hands-on exercises, participants will get to know different Image AI tools, develop effective prompting strategies and critically reflect on the aesthetic, ethical and copyright implications of these technologies. The workshop combines experimental work with in-depth background knowledge on the current development of generative image processes.

## Tutorials and teaching methods

This website provides a range of tutorials and ressources, organized by topic and in increasing order of difficulty.

[Tutorial overview]({% link content/tutorials/tutorials.md %}){: .btn .btn-green
 target="_blank"}

A typical day of teaching starts with a lecture on a topic, followed by a hands-on session where students can apply the concepts learned in the lecture. The hands-on sessions are based on the tutorials provided on this website.

## Evaluation and ECTS

You will earn **2 ECTS** for the validation of the course.

The evaluation will be based on:
- **Attendance**: you must attend at least 4/6 days of teaching. Attending the first day of the course is mandatory.
- **Completion of in-class practical work**: 
    - HM students must submit 3/4 of the completed practical work by the end of the course. The first assignment is mandatory.
    - HMTM students must submit the first assignment A1.

If you do not finish during the in-class sessions, you will have to finish it at home. Asigments must be uploaded all at once on the [following link](https://syncandshare.lrz.de/getlink/fi5NrguA2bdS2RCbRUxV4S/) and before the 10th of July. The **password** will be provided in the course.

<!-- ## Credits and attributions

The tutorial are based on several **open-source tools and libraries** developed by talented researchers and developers. Without them, this course would not be possible. 
Discover all of them in section [Credits and attributions](/docs/credits){: target="_blank"}. -->

## License

The new teaching material (tutorials and code) created for the course is available under the [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/).
**Each tool and library demonstrated in the tutorials is subject to its own license.**
